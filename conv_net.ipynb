{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logo Impressions\n",
    "\n",
    "\n",
    "__First Impression:__\n",
    "\n",
    "To understand if there is any relation of logo's(120, 120, 4) and their impression with people. So, I have taken few logo's from following website. Source: http://www.logosdatabase.com/top-500-logos\n",
    "\n",
    "\n",
    "__Goal:__\n",
    "\n",
    "To build a Conv net classifier that, that can seperate images based on their logo popularity.\n",
    "\n",
    "I took top 0-100 logo's and 400-500 logo's as class A and class B and try then try to make a classificaiton model to predict if a logo is given where will my model fit it.\n",
    "\n",
    "__Future Scope:__\n",
    "\n",
    "* Logo impression ranking.\n",
    "* Help users to create better attractive designs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# os libs\n",
    "import glob\n",
    "\n",
    "# plotting libs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# machine learning libs\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_image_id(full_filename):\n",
    "    full_filename =  full_filename.split('/')[-1].split('.')[0]\n",
    "    if '_' in full_filename:\n",
    "        image_id = full_filename.split('_')[-1]\n",
    "        if image_id.isdigit():\n",
    "            return int(image_id)\n",
    "    return np.NAN\n",
    "\n",
    "def get_image_data(filename):\n",
    "    if filename in ['data/Top 500 Logos_files/interrelated_logo_3652.gif',\n",
    "                   'data/Top 500 Logos_files/veo_logo_3654.gif']:\n",
    "        return\n",
    "    return plt.imread(filename)\n",
    "\n",
    "\n",
    "def get_image_shape(filename):\n",
    "    try:\n",
    "        # Reading Image\n",
    "        x = get_image_data(filename)\n",
    "        return x.shape\n",
    "    except:\n",
    "        return np.NAN\n",
    "    \n",
    "def get_reshaped_image_data(filename):\n",
    "    # Reading Image\n",
    "    x = get_image_data(filename)\n",
    "\n",
    "    # Reshaping\n",
    "    #    Let the Neural Netword do that optimisations stuff\n",
    "    a, b, c = x.shape\n",
    "    y = np.zeros([120, 120, 4])\n",
    "    y[:a, :b, :c] = x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>image_rank</th>\n",
       "      <th>image_class</th>\n",
       "      <th>image_shape</th>\n",
       "      <th>image_shape_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/Top 500 Logos_files/abba_logo_2980.gif</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>A</td>\n",
       "      <td>(32, 120, 4)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/Top 500 Logos_files/aegon_logo_2619.gif</td>\n",
       "      <td>2619.0</td>\n",
       "      <td>A</td>\n",
       "      <td>(44, 120, 4)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/Top 500 Logos_files/after_eight_logo_2933...</td>\n",
       "      <td>2933.0</td>\n",
       "      <td>A</td>\n",
       "      <td>(100, 120, 4)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/Top 500 Logos_files/applebees_logo_3276.gif</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>A</td>\n",
       "      <td>(100, 84, 4)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/Top 500 Logos_files/atandt_logo_3180.gif</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>A</td>\n",
       "      <td>(100, 100, 4)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filenames  image_rank image_class  \\\n",
       "0        data/Top 500 Logos_files/abba_logo_2980.gif      2980.0           A   \n",
       "1       data/Top 500 Logos_files/aegon_logo_2619.gif      2619.0           A   \n",
       "2  data/Top 500 Logos_files/after_eight_logo_2933...      2933.0           A   \n",
       "3   data/Top 500 Logos_files/applebees_logo_3276.gif      3276.0           A   \n",
       "4      data/Top 500 Logos_files/atandt_logo_3180.gif      3180.0           A   \n",
       "\n",
       "     image_shape  image_shape_2  \n",
       "0   (32, 120, 4)              4  \n",
       "1   (44, 120, 4)              4  \n",
       "2  (100, 120, 4)              4  \n",
       "3   (100, 84, 4)              4  \n",
       "4  (100, 100, 4)              4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read local file names\n",
    "files_B = glob.glob(\"data/Top 500 Logos 400_files/*\")\n",
    "files_A = glob.glob(\"data/Top 500 Logos_files/*\")\n",
    "\n",
    "df = pd.DataFrame({'filenames':files_A + files_B})\n",
    "\n",
    "# drop all the image we can't id\n",
    "#   as only Logo's have Images ID's\n",
    "df['image_rank'] = df.filenames.map(get_image_id)\n",
    "df = df.dropna()\n",
    "# df = df.drop('image_rank', axis=1)\n",
    "\n",
    "#### Category of Logo's ####\n",
    "df['image_class'] = df.filenames.map(lambda x: 'A' if x in files_A else 'B')\n",
    "\n",
    "df['image_shape'] = df.filenames.map(get_image_shape)\n",
    "# dropping all images we couldn't read\n",
    "df= df[~df.image_shape.isnull()]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# df['image_shape_0'] = df['image_shape'].map(lambda x: min(x[:2]))\n",
    "# df['image_shape_1'] = df['image_shape'].map(lambda x: max(x[:2]))\n",
    "df['image_shape_2'] = df['image_shape'].map(lambda x: x[2])\n",
    "\n",
    "# Taking only 4 layered Images\n",
    "df = df[df.image_shape_2 == 4]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Images that belong to class A 96\n",
      "[info] Images that belong to class B 98\n"
     ]
    }
   ],
   "source": [
    "df = df[['filenames', 'image_class']]\n",
    "\n",
    "df_index = df.index.tolist()\n",
    "class_a_index = df[df.image_class == 'A'].index.tolist()\n",
    "class_b_index = df[df.image_class == 'B'].index.tolist()\n",
    "np.random.shuffle(class_a_index)\n",
    "np.random.shuffle(class_b_index)\n",
    "\n",
    "print('[info] Images that belong to class A', len(class_a_index))\n",
    "print('[info] Images that belong to class B', len(class_b_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test - Train data split\n",
    "test_train_records_split_count = 70\n",
    "train_data = class_a_index[:test_train_records_split_count] + class_b_index[:test_train_records_split_count]\n",
    "test_data = class_a_index[test_train_records_split_count:] + class_b_index[test_train_records_split_count:]\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df['train_data'] = df.index.map(lambda x: x in train_data).tolist()\n",
    "train_df = df[df.train_data][['filenames', 'image_class']].reset_index(drop=True)\n",
    "test_df = df[~df.train_data][['filenames', 'image_class']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Each Image (120, 120, 4)\n"
     ]
    }
   ],
   "source": [
    "trX = train_df.filenames.map(get_reshaped_image_data).values\n",
    "trY = train_df.image_class.map({'A': 0, 'B': 1}).values\n",
    "\n",
    "teX = test_df.filenames.map(get_reshaped_image_data).values\n",
    "teY = test_df.image_class.map({'A': 0, 'B': 1}).values\n",
    "\n",
    "trX = trX.tolist()\n",
    "teX = teX.tolist()\n",
    "trY = trY.tolist()\n",
    "teY = teY.tolist()\n",
    "\n",
    "print('Shape of Each Image', trX[1].shape)\n",
    "\n",
    "trY = np.array(trY).reshape([len(trY), 1])\n",
    "teY = np.array(teY).reshape([len(teY), 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def model(X, p_keep_conv, p_keep_hidden):\n",
    "    # X shape=(?, 120, 120, 4)\n",
    "    w = init_weights([3, 3, 4, 32])       # 3x3x4 conv, 32 outputs\n",
    "    w2 = init_weights([3, 3, 32, 64])     # 3x3x32 conv, 64 outputs\n",
    "    w3 = init_weights([3, 3, 64, 128])    # 3x3x32 conv, 128 outputs\n",
    "    w4 = init_weights([128 * 4 * 4, 625]) # FC 128 * 4 * 4 inputs, 625 outputs\n",
    "    w_o = init_weights([625, 1])          # FC 625 inputs, 10 outputs (labels)\n",
    "\n",
    "    ############################################################### layer 1\n",
    "    # l1a shape=(?, 120, 120, 32)\n",
    "    l1a = tf.nn.relu(tf.nn.conv2d(X,\n",
    "                                  w,\n",
    "                                  strides=[1, 1, 1, 1],\n",
    "                                  padding='SAME'))\n",
    "    # l1 shape=(?, 30, 30, 32)\n",
    "    l1 = tf.nn.max_pool(l1a,\n",
    "                        ksize=[1, 4, 4, 1],\n",
    "                        strides=[1, 4, 4, 1],\n",
    "                        padding='SAME')\n",
    "    l1 = tf.nn.dropout(l1, p_keep_conv)\n",
    "\n",
    "    ############################################################### layer 2\n",
    "    # l2a shape=(?, 30, 30, 64)\n",
    "    l2a = tf.nn.relu(tf.nn.conv2d(l1,\n",
    "                                  w2,\n",
    "                                  strides=[1, 1, 1, 1],\n",
    "                                  padding='SAME'))\n",
    "    # l2 shape=(?, 15, 15, 64)\n",
    "    l2 = tf.nn.max_pool(l2a,\n",
    "                        ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1],\n",
    "                        padding='SAME')\n",
    "    l2 = tf.nn.dropout(l2, p_keep_conv)\n",
    "\n",
    "    ############################################################### layer 3\n",
    "    # l3a shape=(?, 15, 15, 128)\n",
    "    l3a = tf.nn.relu(tf.nn.conv2d(l2,\n",
    "                                  w3,\n",
    "                                  strides=[1, 1, 1, 1],\n",
    "                                  padding='SAME'))\n",
    "    # l3 shape=(?, 4, 4, 128)\n",
    "    l3 = tf.nn.max_pool(l3a,\n",
    "                        ksize=[1, 4, 4, 1],\n",
    "                        strides=[1, 4, 4, 1],\n",
    "                        padding='SAME')\n",
    "    # reshape to (?, 2048)\n",
    "    l3 = tf.reshape(l3, [-1, w4.get_shape().as_list()[0]])\n",
    "    l3 = tf.nn.dropout(l3, p_keep_conv)\n",
    "    \n",
    "    ############################################################### layer 4 - output\n",
    "    l4 = tf.nn.relu(tf.matmul(l3, w4))\n",
    "    l4 = tf.nn.dropout(l4, p_keep_hidden)\n",
    "\n",
    "    pyx = tf.matmul(l4, w_o)\n",
    "    return pyx\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 120, 120, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "p_keep_conv = tf.placeholder(\"float\")\n",
    "p_keep_hidden = tf.placeholder(\"float\")\n",
    "py_x = model(X, p_keep_conv, p_keep_hidden)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y))\n",
    "train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "predict_op = tf.argmax(py_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 \tScore: 1.0\n",
      "Iter: 1 \tScore: 1.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "test_size = 54\n",
    "\n",
    "trX = np.array(trX)\n",
    "trY = np.array(trY)\n",
    "\n",
    "teX = np.array(teX)\n",
    "teY = np.array(teY)\n",
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for i in range(2):\n",
    "        training_batch = zip(range(0, len(trX), batch_size),\n",
    "                             range(batch_size, len(trX)+1, batch_size))\n",
    "        for start, end in training_batch:\n",
    "            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end],\n",
    "                                          p_keep_conv: 0.5, p_keep_hidden: 0.5})\n",
    "\n",
    "        test_indices = np.arange(len(teX)) # Get A Test Batch\n",
    "        np.random.shuffle(test_indices)\n",
    "        test_indices = test_indices[0:test_size]\n",
    "\n",
    "        print('Iter:', i, '\\tScore:', np.mean(np.argmax(teY[test_indices], axis=1) ==\n",
    "                         sess.run(predict_op, feed_dict={X: teX[test_indices],\n",
    "                                                         Y: teY[test_indices],\n",
    "                                                         p_keep_conv: 1.0,\n",
    "                                                         p_keep_hidden: 1.0})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
